{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51f90f6",
   "metadata": {},
   "source": [
    "# Machine Leanring Assignment 3: Tweet Sentiment Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from random import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c047f",
   "metadata": {},
   "source": [
    "## Read Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80deccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDictionary(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        tweet_kv = [(str(tup[0]), tup[1]) for tup in tweet_list]\n",
    "        tweet_dict = dict(tweet_kv)\n",
    "        data.at[i, \"tweet\"] = tweet_dict\n",
    "        i += 1\n",
    "        \n",
    "    return data\n",
    "\n",
    "def convertToList(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        data.at[i, \"tweet\"] = tweet_list\n",
    "        i += 1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ec12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DEV DATA\n",
    "# ********************** CHANGE TO SAME FOLDER ********************************************\n",
    "# 1. TFIDF\n",
    "f_dev_data = pd.read_csv(\"data/data/dev_tfidf.csv\")\n",
    "f_dev_data = convertToDictionary(f_dev_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_dev_data = pd.read_csv(\"data/data/dev_glove.csv\")\n",
    "g_dev_data = convertToList(g_dev_data)\n",
    "\n",
    "# 3. Count\n",
    "c_dev_data = pd.read_csv(\"data/data/dev_count.csv\")\n",
    "c_dev_data = convertToDictionary(c_dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c78a29",
   "metadata": {},
   "source": [
    "## Process Dev Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dda04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "v = DictVectorizer()\n",
    "\n",
    "X_dev_f = v.fit_transform(f_dev_data[\"tweet\"])\n",
    "y_dev_f = f_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_g = g_dev_data[\"tweet\"].to_list()\n",
    "y_dev_g = g_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_c = v.fit_transform(c_dev_data[\"tweet\"])\n",
    "y_dev_c = c_dev_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ff9c1",
   "metadata": {},
   "source": [
    "## Train Models - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148fd131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'pos', ..., 'neu', 'neu', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELS - DEV\n",
    "\n",
    "# tfidf\n",
    "lr_dev_f = LogisticRegression().fit(X_dev_f, y_dev_f)\n",
    "lr_dev_f.predict(X_dev_f)\n",
    "\n",
    "mnb_dev_f = MultinomialNB().fit(X_dev_f,y_dev_f)\n",
    "mnb_dev_f.predict(X_dev_f)\n",
    "\n",
    "mlp_dev_f = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp_dev_f.fit(X_dev_f, y_dev_f)\n",
    "mlp_dev_f.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c17ad16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos', 'pos', ..., 'neu', 'neg', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glove\n",
    "lr_dev_g = LogisticRegression().fit(X_dev_g, y_dev_g)\n",
    "lr_dev_g.predict(X_dev_g)\n",
    "\n",
    "# Don't use Naive Baynes due to conditional indepednence assumption.\n",
    "# These features are inherently related as all 100 represent the same word\n",
    "# mnb_dev_g = MultinomialNB().fit(X_dev_g,y_dev_g)\n",
    "# mnb_dev_g.predict(X_dev_g)\n",
    "\n",
    "mlp_dev_g = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(50,), random_state=1)\n",
    "\n",
    "mlp_dev_g.fit(X_dev_g, y_dev_g)\n",
    "mlp_dev_g.predict(X_dev_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73678ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'pos', ..., 'neu', 'neu', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "lr_dev_c = LogisticRegression().fit(X_dev_c, y_dev_c)\n",
    "lr_dev_c.predict(X_dev_c)\n",
    "\n",
    "mnb_dev_c = MultinomialNB().fit(X_dev_c,y_dev_c)\n",
    "mnb_dev_c.predict(X_dev_c)\n",
    "\n",
    "mlp_dev_c = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp_dev_c.fit(X_dev_c, y_dev_c)\n",
    "mlp_dev_c.predict(X_dev_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7292e",
   "metadata": {},
   "source": [
    "## Evaluation - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8f933a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf\n",
      "Logistic Regression Accuracy:\t0.8106601024816639\n",
      "Naive Bayes Accuracy:\t0.7852908670752536\n",
      "Multi-Layer Perceptron:\t0.990304430824877\n",
      "GloVe\n",
      "Logistic Regression Accuracy:\t0.6833618004621722\n",
      "Multi-Layer Perceptron:\t0.7670551592484678\n",
      "Count\n",
      "Logistic Regression Accuracy:\t0.8384406711544258\n",
      "Naive Bayes Accuracy:\t0.7846880337586657\n",
      "Multi-Layer Perceptron:\t0.9948256806992867\n"
     ]
    }
   ],
   "source": [
    "print(\"Tfidf\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_dev_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_dev_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_dev_f.score(X_dev_f, y_dev_f)))\n",
    "\n",
    "print(\"GloVe\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_dev_g.score(X_dev_g, y_dev_g)))\n",
    "# print(\"Naive Bayes Accuracy:\\t\" + str(mnb_dev_g.score(X_dev_g, y_dev_g)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_dev_g.score(X_dev_g, y_dev_g)))\n",
    "\n",
    "print(\"Count\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_dev_c.score(X_dev_c, y_dev_c)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_dev_c.score(X_dev_c, y_dev_c)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_dev_c.score(X_dev_c, y_dev_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a2083",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. Mutli-Layer Perceptron performing the best\n",
    "2. GloVe embeddings not performing well on current models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896af18e",
   "metadata": {},
   "source": [
    "## Baseline Evaluation  on Dev Dataset\n",
    "Check each model performs better than the naive baseline model. One-R in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5aedf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-R implementation\n",
    "import random\n",
    "\n",
    "def weight_random(y_dev):\n",
    "    error = 0    \n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random.choice(y_dev)\n",
    "\n",
    "#         print(prediction, label)\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect\n",
    "\n",
    "count_pos = Counter(y_dev_f)['pos'] \n",
    "count_neg = Counter(y_dev_f)['neg'] \n",
    "count_neu = Counter(y_dev_f)['neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5e98b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7157 correct predicitons,  12749 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6404601628\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_f)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ebcde0a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'choice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-2ecb2382da16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dev_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"There are\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"positive, \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_neg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"negative, and\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount_neu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"neutral dev instances\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"correct predicitons, \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"incorrect predictions\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The prior probability of positive is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprior_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The prior probability of negative is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprior_neg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-146-27c7c1005633>\u001b[0m in \u001b[0;36mweight_random\u001b[1;34m(y_dev)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mincorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_dev\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#         print(prediction, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'choice'"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_g)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_c)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3c93c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "# Determine class distirbutions\n",
    "prior_pos = Counter(y_dev_f)['pos'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neg = Counter(y_dev_f)['neg'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neu = Counter(y_dev_f)['neu'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "\n",
    "def weight_random2(y_dev,prior_pos,prior_neg):\n",
    "    pos_boundary = prior_pos\n",
    "    neg_boundary = prior_pos + prior_neg\n",
    "    \n",
    "    error = 0    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random()\n",
    "        if(prediction <= pos_boundary):\n",
    "            prediction = 'pos'  \n",
    "        elif(pos_boundary < prediction <= neg_boundary):\n",
    "            prediction = 'neg'\n",
    "        else:\n",
    "            prediction = 'neu'\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c981c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7084 correct predicitons,  12822 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6441273988\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random2(y_dev_f, prior_pos, prior_neg)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4ee64b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3632573093539636"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_dev_f, y_dev_f)\n",
    "dummy_clf.score(X_dev_f, y_dev_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298f289",
   "metadata": {},
   "source": [
    "## Selecting Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f151c",
   "metadata": {},
   "source": [
    "The analysis of the dev dataset suggested that the Multi-Layer Perceptron was the most suitable model for this classification task, hence we select this model the train with the training dataset.\n",
    "Feature selection best option was ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fb07f",
   "metadata": {},
   "source": [
    "## Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1647d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN DATA\n",
    "# 1. TFIDF\n",
    "f_data = pd.read_csv(\"data/data/train_tfidf.csv\")\n",
    "\n",
    "# Convert each tweet into a dictionary for processing\n",
    "f_data = convertToDictionary(f_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_data = pd.read_csv(\"data/data/train_glove.csv\")\n",
    "g_data = convertToList(g_data)\n",
    "\n",
    "# 3. Count\n",
    "c_data = pd.read_csv(\"data/data/train_count.csv\")\n",
    "c_data = convertToDictionary(c_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac4d2f",
   "metadata": {},
   "source": [
    "## Process Train Input\n",
    "Prepare the features which performed the best during dev evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19345c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7761a7e2",
   "metadata": {},
   "source": [
    "## Train Model \n",
    "Prepare best performing model from dev evaluation and train of full training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc85e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS - TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ed58e",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Test selected model against the test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS - TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
