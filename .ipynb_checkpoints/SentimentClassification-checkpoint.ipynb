{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51f90f6",
   "metadata": {},
   "source": [
    "# Machine Leanring Assignment 3: Tweet Sentiment Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "290a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from random import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629678f",
   "metadata": {},
   "source": [
    "## Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "40fb9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDictionary(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        tweet_kv = [(str(tup[0]), tup[1]) for tup in tweet_list]\n",
    "        tweet_dict = dict(tweet_kv)\n",
    "        data.at[i, \"tweet\"] = tweet_dict\n",
    "        i += 1\n",
    "        \n",
    "    return data\n",
    "\n",
    "def convertToList(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        data.at[i, \"tweet\"] = tweet_list\n",
    "        i += 1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d66bd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN DATA\n",
    "# 1. TFIDF\n",
    "f_train_data = pd.read_csv(\"data/data/train_tfidf.csv\")\n",
    "\n",
    "# Convert each tweet into a dictionary for processing\n",
    "f_train_data = convertToDictionary(f_train_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_train_data = pd.read_csv(\"data/data/train_glove.csv\")\n",
    "g_train_data = convertToList(g_train_data)\n",
    "\n",
    "# 3. Count\n",
    "c_train_data = pd.read_csv(\"data/data/train_count.csv\")\n",
    "c_train_data = convertToDictionary(c_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4304c",
   "metadata": {},
   "source": [
    "## Process Training Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "267a63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "v = DictVectorizer()\n",
    "\n",
    "X_train_f = v.fit_transform(f_train_data[\"tweet\"])\n",
    "y_train_f = f_train_data[\"sentiment\"]\n",
    "\n",
    "X_train_g = g_train_data[\"tweet\"].to_list()\n",
    "y_train_g = g_train_data[\"sentiment\"]\n",
    "\n",
    "X_train_c = v.fit_transform(c_train_data[\"tweet\"])\n",
    "y_train_c = c_train_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d44e48",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e9da9",
   "metadata": {},
   "source": [
    "### 1 . TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5df2ba",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "811a83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_f = LogisticRegression().fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81854269",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1519d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_f = MultinomialNB().fit(X_train_f,y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54088563",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2c2f0bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5,), random_state=1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was using (15,) hidden layers for excellent performance\n",
    "mlp_f = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5,), random_state=1)\n",
    "\n",
    "mlp_f.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6875f3a",
   "metadata": {},
   "source": [
    "### 2. GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063966c4",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92096564",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_g = LogisticRegression().fit(X_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd79db",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_g = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(50,), random_state=1)\n",
    "\n",
    "mlp_g.fit(X_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084bd99",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "Don't use Naive Baynes due to conditional indepednence assumption.\n",
    "These features are inherently related as all 100 represent the same word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ba91e",
   "metadata": {},
   "source": [
    "### 3. Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa1d7b",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31270079",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_c = LogisticRegression().fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7415b2",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_c = MultinomialNB().fit(X_train_c,y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e230e07",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_c = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5,), random_state=1)\n",
    "\n",
    "mlp_c.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c047f",
   "metadata": {},
   "source": [
    "## Read Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d0ec12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DEV DATA\n",
    "# ********************** CHANGE TO SAME FOLDER ********************************************\n",
    "# 1. TFIDF\n",
    "f_dev_data = pd.read_csv(\"data/data/dev_tfidf.csv\")\n",
    "f_dev_data = convertToDictionary(f_dev_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_dev_data = pd.read_csv(\"data/data/dev_glove.csv\")\n",
    "g_dev_data = convertToList(g_dev_data)\n",
    "\n",
    "# 3. Count\n",
    "c_dev_data = pd.read_csv(\"data/data/dev_count.csv\")\n",
    "c_dev_data = convertToDictionary(c_dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c78a29",
   "metadata": {},
   "source": [
    "## Process Dev Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8dda04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "v = DictVectorizer()\n",
    "\n",
    "# Need to make the sparse matrix the same size\n",
    "\n",
    "X_dev_f = v.fit_transform(f_dev_data[\"tweet\"])\n",
    "y_dev_f = f_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_g = g_dev_data[\"tweet\"].to_list()\n",
    "y_dev_g = g_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_c = v.fit_transform(c_dev_data[\"tweet\"])\n",
    "y_dev_c = c_dev_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ff9c1",
   "metadata": {},
   "source": [
    "## Predictions - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "148fd131",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4949 features per sample; expecting 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-1a8836eebd9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# tfidf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmnb_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4949 features per sample; expecting 5000"
     ]
    }
   ],
   "source": [
    "# MODELS - DEV\n",
    "\n",
    "# tfidf\n",
    "lr_f.predict(X_dev_f)\n",
    "\n",
    "mnb_f.predict(X_dev_f)\n",
    "\n",
    "mlp_f.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c17ad16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos', 'pos', ..., 'neu', 'neg', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glove\n",
    "lr_g.predict(X_dev_g)\n",
    "\n",
    "# Don't use Naive Baynes due to conditional indepednence assumption.\n",
    "# These features are inherently related as all 100 represent the same word\n",
    "# mnb_dev_g = MultinomialNB().fit(X_dev_g,y_dev_g)\n",
    "# mnb_dev_g.predict(X_dev_g)\n",
    "\n",
    "mlp_g.predict(X_dev_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73678ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'pos', ..., 'neu', 'neu', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "lr_c.predict(X_dev_c)\n",
    "\n",
    "mnb_c.predict(X_dev_c)\n",
    "\n",
    "mlp_c.predict(X_dev_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7292e",
   "metadata": {},
   "source": [
    "## Evaluation - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8f933a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf\n",
      "Logistic Regression Accuracy:\t0.8106601024816639\n",
      "Naive Bayes Accuracy:\t0.7852908670752536\n",
      "Multi-Layer Perceptron:\t0.990304430824877\n",
      "GloVe\n",
      "Logistic Regression Accuracy:\t0.6833618004621722\n",
      "Multi-Layer Perceptron:\t0.7670551592484678\n",
      "Count\n",
      "Logistic Regression Accuracy:\t0.8384406711544258\n",
      "Naive Bayes Accuracy:\t0.7846880337586657\n",
      "Multi-Layer Perceptron:\t0.9948256806992867\n"
     ]
    }
   ],
   "source": [
    "print(\"Tfidf\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_f.score(X_dev_f, y_dev_f)))\n",
    "\n",
    "print(\"GloVe\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_g.score(X_dev_g, y_dev_g)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_g.score(X_dev_g, y_dev_g)))\n",
    "\n",
    "print(\"Count\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_c.score(X_dev_c, y_dev_c)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_c.score(X_dev_c, y_dev_c)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_c.score(X_dev_c, y_dev_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a2083",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. Mutli-Layer Perceptron performing the best\n",
    "2. GloVe embeddings not performing well on current models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a60a62",
   "metadata": {},
   "source": [
    "## Baseline Evaluation\n",
    "Check each model performs better than the naive baseline model. One-R in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "555f3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-R implementation\n",
    "import random\n",
    "\n",
    "def weight_random(y_dev):\n",
    "    error = 0    \n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random.choice(y_dev)\n",
    "\n",
    "#         print(prediction, label)\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect\n",
    "\n",
    "count_pos = Counter(y_dev_f)['pos'] \n",
    "count_neg = Counter(y_dev_f)['neg'] \n",
    "count_neu = Counter(y_dev_f)['neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7fec9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7107 correct predicitons,  12799 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6429719683\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_f)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1b19f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7068 correct predicitons,  12838 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6449311765\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_g)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6dcd29b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7229 correct predicitons,  12677 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6368431629\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_c)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "db389712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "# Determine class distirbutions\n",
    "prior_pos = Counter(y_dev_f)['pos'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neg = Counter(y_dev_f)['neg'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neu = Counter(y_dev_f)['neu'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "\n",
    "def weight_random2(y_dev,prior_pos,prior_neg):\n",
    "    pos_boundary = prior_pos\n",
    "    neg_boundary = prior_pos + prior_neg\n",
    "    \n",
    "    error = 0    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random()\n",
    "        if(prediction <= pos_boundary):\n",
    "            prediction = 'pos'  \n",
    "        elif(pos_boundary < prediction <= neg_boundary):\n",
    "            prediction = 'neg'\n",
    "        else:\n",
    "            prediction = 'neu'\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f81e7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7313 correct predicitons,  12593 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6326233296\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random2(y_dev_f, prior_pos, prior_neg)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "85cda3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3632573093539636"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_dev_f, y_dev_f)\n",
    "dummy_clf.score(X_dev_f, y_dev_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001aa34",
   "metadata": {},
   "source": [
    "## Selecting Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ec27a",
   "metadata": {},
   "source": [
    "The analysis of the dev dataset suggested that the Multi-Layer Perceptron was the most suitable model for this classification task, hence we select this model the train with the training dataset.\n",
    "Feature selection best option was ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7b289",
   "metadata": {},
   "source": [
    "## Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282733c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18842a8",
   "metadata": {},
   "source": [
    "## Process Train Input\n",
    "Prepare the features which performed the best during dev evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3207cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8365fedf",
   "metadata": {},
   "source": [
    "## Train Model \n",
    "Prepare best performing model from dev evaluation and train of full training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc85e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS - TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513b555",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Test selected model against the test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS - TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
