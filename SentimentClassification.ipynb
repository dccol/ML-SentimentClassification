{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51f90f6",
   "metadata": {},
   "source": [
    "# Machine Leanring Assignment 3: Tweet Sentiment Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "290a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from random import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546fedb",
   "metadata": {},
   "source": [
    "# TRAINING PHASE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97cf1e",
   "metadata": {},
   "source": [
    "## Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f436e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDictionary(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        tweet_kv = [(str(tup[0]), tup[1]) for tup in tweet_list]\n",
    "        tweet_dict = dict(tweet_kv)\n",
    "        data.at[i, \"tweet\"] = tweet_dict\n",
    "        i += 1\n",
    "        \n",
    "    return data\n",
    "\n",
    "def convertToList(data):\n",
    "    i = 0\n",
    "    for tweet in data[\"tweet\"]:\n",
    "        tweet_list = ast.literal_eval(tweet)\n",
    "        data.at[i, \"tweet\"] = tweet_list\n",
    "        i += 1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ac9d35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN DATA\n",
    "# 1. TFIDF\n",
    "f_train_data = pd.read_csv(\"data/data/train_tfidf.csv\")\n",
    "\n",
    "# Convert each tweet into a dictionary for processing\n",
    "f_train_data = convertToDictionary(f_train_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_train_data = pd.read_csv(\"data/data/train_glove.csv\")\n",
    "g_train_data = convertToList(g_train_data)\n",
    "\n",
    "# 3. Count\n",
    "c_train_data = pd.read_csv(\"data/data/train_count.csv\")\n",
    "c_train_data = convertToDictionary(c_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a79e6",
   "metadata": {},
   "source": [
    "## Process Training Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b1a229f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "v = DictVectorizer()\n",
    "\n",
    "X_train_f = v.fit_transform(f_train_data[\"tweet\"])\n",
    "y_train_f = f_train_data[\"sentiment\"]\n",
    "\n",
    "X_train_g = g_train_data[\"tweet\"].to_list()\n",
    "y_train_g = g_train_data[\"sentiment\"]\n",
    "\n",
    "X_train_c = v.fit_transform(c_train_data[\"tweet\"])\n",
    "y_train_c = c_train_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a8acf",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "Models were trained on each of the three given feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04935055",
   "metadata": {},
   "source": [
    "### 1 . TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8050890",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8ea285ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_f = LogisticRegression().fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc69d06",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4d5016ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_f = MultinomialNB().fit(X_train_f,y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf123896",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "39c0e698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(3,), random_state=1)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was using (15,) hidden layers for excellent performance\n",
    "mlp_f = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(3,), random_state=1)\n",
    "\n",
    "mlp_f.fit(X_train_f, y_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5b0f3",
   "metadata": {},
   "source": [
    "### 2. GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb339918",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "11b7851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_g = LogisticRegression().fit(X_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed2841",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d828819",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_g = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(50,), random_state=1)\n",
    "\n",
    "mlp_g.fit(X_train_g, y_train_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f778f",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "Don't use Naive Baynes due to conditional indepednence assumption.\n",
    "These features are inherently related as all 100 represent the same word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1d245",
   "metadata": {},
   "source": [
    "### 3. Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370be693",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "bcb4891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcole\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_c = LogisticRegression().fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa8ea7",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "65704e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_c = MultinomialNB().fit(X_train_c,y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c42acd",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5def5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_c = MLPClassifier(alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5,), random_state=1)\n",
    "\n",
    "mlp_c.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811aa69e",
   "metadata": {},
   "source": [
    "# DEVELOPMENT PHASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c047f",
   "metadata": {},
   "source": [
    "## Read Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d0ec12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DEV DATA\n",
    "# ********************** CHANGE TO SAME FOLDER ********************************************\n",
    "# 1. TFIDF\n",
    "f_dev_data = pd.read_csv(\"data/data/dev_tfidf.csv\")\n",
    "f_dev_data = convertToDictionary(f_dev_data)\n",
    "\n",
    "# 2. GloVe\n",
    "g_dev_data = pd.read_csv(\"data/data/dev_glove.csv\")\n",
    "g_dev_data = convertToList(g_dev_data)\n",
    "\n",
    "# 3. Count\n",
    "c_dev_data = pd.read_csv(\"data/data/dev_count.csv\")\n",
    "c_dev_data = convertToDictionary(c_dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c78a29",
   "metadata": {},
   "source": [
    "## Process Dev Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8dda04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "X_dev_f = v.transform(f_dev_data[\"tweet\"])\n",
    "y_dev_f = f_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_g = g_dev_data[\"tweet\"].to_list()\n",
    "y_dev_g = g_dev_data[\"sentiment\"]\n",
    "\n",
    "X_dev_c = v.transform(c_dev_data[\"tweet\"])\n",
    "y_dev_c = c_dev_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ff9c1",
   "metadata": {},
   "source": [
    "## Predictions - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "148fd131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'pos', ..., 'neu', 'neg', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELS - DEV\n",
    "# tfidf\n",
    "lr_f.predict(X_dev_f)\n",
    "\n",
    "mnb_f.predict(X_dev_f)\n",
    "\n",
    "mlp_f.predict(X_dev_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c17ad16c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-697de0493c82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# mnb_dev_g.predict(X_dev_g)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmlp_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp_g' is not defined"
     ]
    }
   ],
   "source": [
    "# glove\n",
    "lr_g.predict(X_dev_g)\n",
    "\n",
    "# Don't use Naive Baynes due to conditional indepednence assumption.\n",
    "# These features are inherently related as all 100 represent the same word\n",
    "# mnb_dev_g = MultinomialNB().fit(X_dev_g,y_dev_g)\n",
    "# mnb_dev_g.predict(X_dev_g)\n",
    "\n",
    "mlp_g.predict(X_dev_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "73678ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-301-b72e70f9191f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmnb_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmlp_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp_c' is not defined"
     ]
    }
   ],
   "source": [
    "# count\n",
    "lr_c.predict(X_dev_c)\n",
    "\n",
    "mnb_c.predict(X_dev_c)\n",
    "\n",
    "mlp_c.predict(X_dev_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7292e",
   "metadata": {},
   "source": [
    "## Evaluation - DEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e8f933a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf\n",
      "Logistic Regression Accuracy:\t0.7419873405003516\n",
      "Naive Bayes Accuracy:\t0.7256103687330453\n",
      "Multi-Layer Perceptron:\t0.7368130211996383\n",
      "GloVe\n",
      "Logistic Regression Accuracy:\t0.6789410228071938\n",
      "Count\n",
      "Logistic Regression Accuracy:\t0.7406812016477444\n",
      "Naive Bayes Accuracy:\t0.7307846880337586\n"
     ]
    }
   ],
   "source": [
    "print(\"Tfidf\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_f.score(X_dev_f, y_dev_f)))\n",
    "print(\"Multi-Layer Perceptron:\\t\" + str(mlp_f.score(X_dev_f, y_dev_f)))\n",
    "\n",
    "print(\"GloVe\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_g.score(X_dev_g, y_dev_g)))\n",
    "# print(\"Multi-Layer Perceptron:\\t\" + str(mlp_g.score(X_dev_g, y_dev_g)))\n",
    "\n",
    "print(\"Count\")\n",
    "print(\"Logistic Regression Accuracy:\\t\" + str(lr_c.score(X_dev_c, y_dev_c)))\n",
    "print(\"Naive Bayes Accuracy:\\t\" + str(mnb_c.score(X_dev_c, y_dev_c)))\n",
    "# print(\"Multi-Layer Perceptron:\\t\" + str(mlp_c.score(X_dev_c, y_dev_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a2083",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. Mutli-Layer Perceptron performing the best\n",
    "2. GloVe embeddings not performing well on current models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd003df0",
   "metadata": {},
   "source": [
    "## Baseline Evaluation\n",
    "Check each model performs better than the naive baseline model. One-R in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2acdb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-R implementation\n",
    "import random\n",
    "\n",
    "def weight_random(y_dev):\n",
    "    error = 0    \n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random.choice(y_dev)\n",
    "\n",
    "#         print(prediction, label)\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect\n",
    "\n",
    "count_pos = Counter(y_dev_f)['pos'] \n",
    "count_neg = Counter(y_dev_f)['neg'] \n",
    "count_neu = Counter(y_dev_f)['neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b9623531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7107 correct predicitons,  12799 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6429719683\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_f)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b0632db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7068 correct predicitons,  12838 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6449311765\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_g)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cc18dff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7229 correct predicitons,  12677 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6368431629\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random(y_dev_c)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7d1d6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "# Determine class distirbutions\n",
    "prior_pos = Counter(y_dev_f)['pos'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neg = Counter(y_dev_f)['neg'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "prior_neu = Counter(y_dev_f)['neu'] / (Counter(y_dev_f)['pos'] + Counter(y_dev_f)['neg'] + Counter(y_dev_f)['neu'])\n",
    "\n",
    "def weight_random2(y_dev,prior_pos,prior_neg):\n",
    "    pos_boundary = prior_pos\n",
    "    neg_boundary = prior_pos + prior_neg\n",
    "    \n",
    "    error = 0    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for label in y_dev:\n",
    "        prediction = random()\n",
    "        if(prediction <= pos_boundary):\n",
    "            prediction = 'pos'  \n",
    "        elif(pos_boundary < prediction <= neg_boundary):\n",
    "            prediction = 'neg'\n",
    "        else:\n",
    "            prediction = 'neu'\n",
    "        if(prediction == label):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    error = incorrect / len(y_dev)\n",
    " \n",
    "    return error, correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "05632985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7916 positive,  8095 negative, and 3895 neutral dev instances\n",
      "7313 correct predicitons,  12593 incorrect predictions\n",
      "The prior probability of positive is 0.39767\n",
      "The prior probability of negative is 0.40666\n",
      "The prior probability of neutral is 0.19567\n",
      "The weighted random baseline's error is: 0.6326233296\n"
     ]
    }
   ],
   "source": [
    "error, correct, incorrect = weight_random2(y_dev_f, prior_pos, prior_neg)\n",
    "print(\"There are\",count_pos,\"positive, \", count_neg,\"negative, and\",count_neu, \"neutral dev instances\")\n",
    "print(correct, \"correct predicitons, \",incorrect,\"incorrect predictions\" )\n",
    "print(\"The prior probability of positive is\", round(prior_pos,5))\n",
    "print(\"The prior probability of negative is\", round(prior_neg,5))\n",
    "print(\"The prior probability of neutral is\", round(prior_neu,5))\n",
    "print(\"The weighted random baseline's error is:\", round(error,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2452d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3632573093539636"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_dev_f, y_dev_f)\n",
    "dummy_clf.score(X_dev_f, y_dev_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5395f1d4",
   "metadata": {},
   "source": [
    "## Selecting Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89db383",
   "metadata": {},
   "source": [
    "The analysis of the dev dataset suggested that the Multi-Layer Perceptron was the most suitable model for this classification task, hence we select this model the train with the training dataset.\n",
    "Feature selection best option was ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a89ab",
   "metadata": {},
   "source": [
    "## Tuning Selected Model\n",
    "Optimise parameters for best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca736c6",
   "metadata": {},
   "source": [
    "# TESTING PHASE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd812024",
   "metadata": {},
   "source": [
    "## Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c23c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58493c35",
   "metadata": {},
   "source": [
    "## Process Test Input\n",
    "Prepare the features which performed the best during dev evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315b70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf9ad52d",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Test selected model against the test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS - TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
